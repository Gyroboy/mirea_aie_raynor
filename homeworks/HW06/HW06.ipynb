{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b90a4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import json \n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a1685c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 30 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      15000 non-null  int64  \n",
      " 1   f01     15000 non-null  float64\n",
      " 2   f02     15000 non-null  float64\n",
      " 3   f03     15000 non-null  float64\n",
      " 4   f04     15000 non-null  float64\n",
      " 5   f05     15000 non-null  float64\n",
      " 6   f06     15000 non-null  float64\n",
      " 7   f07     15000 non-null  float64\n",
      " 8   f08     15000 non-null  float64\n",
      " 9   f09     15000 non-null  float64\n",
      " 10  f10     15000 non-null  float64\n",
      " 11  f11     15000 non-null  float64\n",
      " 12  f12     15000 non-null  float64\n",
      " 13  f13     15000 non-null  float64\n",
      " 14  f14     15000 non-null  float64\n",
      " 15  f15     15000 non-null  float64\n",
      " 16  f16     15000 non-null  float64\n",
      " 17  f17     15000 non-null  float64\n",
      " 18  f18     15000 non-null  float64\n",
      " 19  f19     15000 non-null  float64\n",
      " 20  f20     15000 non-null  float64\n",
      " 21  f21     15000 non-null  float64\n",
      " 22  f22     15000 non-null  float64\n",
      " 23  f23     15000 non-null  float64\n",
      " 24  f24     15000 non-null  float64\n",
      " 25  f25     15000 non-null  float64\n",
      " 26  f26     15000 non-null  float64\n",
      " 27  f27     15000 non-null  float64\n",
      " 28  f28     15000 non-null  float64\n",
      " 29  target  15000 non-null  int64  \n",
      "dtypes: float64(28), int64(2)\n",
      "memory usage: 3.4 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "      <th>f05</th>\n",
       "      <th>f06</th>\n",
       "      <th>f07</th>\n",
       "      <th>f08</th>\n",
       "      <th>f09</th>\n",
       "      <th>...</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7500.500000</td>\n",
       "      <td>-0.840416</td>\n",
       "      <td>-0.011530</td>\n",
       "      <td>0.755463</td>\n",
       "      <td>0.008092</td>\n",
       "      <td>-0.246559</td>\n",
       "      <td>0.992538</td>\n",
       "      <td>-0.004599</td>\n",
       "      <td>-0.005366</td>\n",
       "      <td>0.011024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>-0.060611</td>\n",
       "      <td>-0.008095</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.699377</td>\n",
       "      <td>-0.001170</td>\n",
       "      <td>1.380216</td>\n",
       "      <td>0.150765</td>\n",
       "      <td>0.612600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4330.271354</td>\n",
       "      <td>1.785432</td>\n",
       "      <td>1.007374</td>\n",
       "      <td>3.663136</td>\n",
       "      <td>0.996556</td>\n",
       "      <td>2.216202</td>\n",
       "      <td>3.943110</td>\n",
       "      <td>2.113607</td>\n",
       "      <td>1.001960</td>\n",
       "      <td>1.006309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988931</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>3.747823</td>\n",
       "      <td>0.994912</td>\n",
       "      <td>0.990567</td>\n",
       "      <td>3.801468</td>\n",
       "      <td>0.996588</td>\n",
       "      <td>3.929134</td>\n",
       "      <td>2.005847</td>\n",
       "      <td>0.740016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.199174</td>\n",
       "      <td>-4.100091</td>\n",
       "      <td>-13.591257</td>\n",
       "      <td>-3.992807</td>\n",
       "      <td>-8.243563</td>\n",
       "      <td>-14.950758</td>\n",
       "      <td>-8.522298</td>\n",
       "      <td>-3.768197</td>\n",
       "      <td>-3.791645</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.612116</td>\n",
       "      <td>-4.150852</td>\n",
       "      <td>-15.977469</td>\n",
       "      <td>-3.664246</td>\n",
       "      <td>-3.857890</td>\n",
       "      <td>-16.273835</td>\n",
       "      <td>-4.536600</td>\n",
       "      <td>-12.105957</td>\n",
       "      <td>-8.300728</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3750.750000</td>\n",
       "      <td>-2.029608</td>\n",
       "      <td>-0.686265</td>\n",
       "      <td>-1.593729</td>\n",
       "      <td>-0.674039</td>\n",
       "      <td>-1.738188</td>\n",
       "      <td>-1.580544</td>\n",
       "      <td>-1.380091</td>\n",
       "      <td>-0.673001</td>\n",
       "      <td>-0.661451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674236</td>\n",
       "      <td>-0.669654</td>\n",
       "      <td>-2.517892</td>\n",
       "      <td>-0.676471</td>\n",
       "      <td>-0.661098</td>\n",
       "      <td>-1.842677</td>\n",
       "      <td>-0.668133</td>\n",
       "      <td>-1.339314</td>\n",
       "      <td>-1.235425</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7500.500000</td>\n",
       "      <td>-0.855943</td>\n",
       "      <td>-0.010454</td>\n",
       "      <td>0.744919</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>-0.203512</td>\n",
       "      <td>1.110848</td>\n",
       "      <td>0.134466</td>\n",
       "      <td>-0.003663</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020916</td>\n",
       "      <td>0.010701</td>\n",
       "      <td>0.019034</td>\n",
       "      <td>-0.001622</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.780608</td>\n",
       "      <td>-0.007763</td>\n",
       "      <td>1.108728</td>\n",
       "      <td>0.137089</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11250.250000</td>\n",
       "      <td>0.313482</td>\n",
       "      <td>0.674347</td>\n",
       "      <td>3.057234</td>\n",
       "      <td>0.677459</td>\n",
       "      <td>1.254102</td>\n",
       "      <td>3.700201</td>\n",
       "      <td>1.443666</td>\n",
       "      <td>0.662753</td>\n",
       "      <td>0.683465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681036</td>\n",
       "      <td>0.676786</td>\n",
       "      <td>2.521745</td>\n",
       "      <td>0.659456</td>\n",
       "      <td>0.663270</td>\n",
       "      <td>3.297387</td>\n",
       "      <td>0.676626</td>\n",
       "      <td>3.869991</td>\n",
       "      <td>1.524830</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15000.000000</td>\n",
       "      <td>7.338969</td>\n",
       "      <td>4.418126</td>\n",
       "      <td>17.965154</td>\n",
       "      <td>3.887820</td>\n",
       "      <td>8.542916</td>\n",
       "      <td>15.618988</td>\n",
       "      <td>7.575797</td>\n",
       "      <td>3.698010</td>\n",
       "      <td>3.963730</td>\n",
       "      <td>...</td>\n",
       "      <td>3.497004</td>\n",
       "      <td>3.828639</td>\n",
       "      <td>12.661894</td>\n",
       "      <td>4.214633</td>\n",
       "      <td>4.378893</td>\n",
       "      <td>17.152063</td>\n",
       "      <td>3.618447</td>\n",
       "      <td>18.906060</td>\n",
       "      <td>8.007400</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           f01           f02           f03           f04  \\\n",
       "count  15000.000000  15000.000000  15000.000000  15000.000000  15000.000000   \n",
       "mean    7500.500000     -0.840416     -0.011530      0.755463      0.008092   \n",
       "std     4330.271354      1.785432      1.007374      3.663136      0.996556   \n",
       "min        1.000000     -8.199174     -4.100091    -13.591257     -3.992807   \n",
       "25%     3750.750000     -2.029608     -0.686265     -1.593729     -0.674039   \n",
       "50%     7500.500000     -0.855943     -0.010454      0.744919      0.009431   \n",
       "75%    11250.250000      0.313482      0.674347      3.057234      0.677459   \n",
       "max    15000.000000      7.338969      4.418126     17.965154      3.887820   \n",
       "\n",
       "                f05           f06           f07           f08           f09  \\\n",
       "count  15000.000000  15000.000000  15000.000000  15000.000000  15000.000000   \n",
       "mean      -0.246559      0.992538     -0.004599     -0.005366      0.011024   \n",
       "std        2.216202      3.943110      2.113607      1.001960      1.006309   \n",
       "min       -8.243563    -14.950758     -8.522298     -3.768197     -3.791645   \n",
       "25%       -1.738188     -1.580544     -1.380091     -0.673001     -0.661451   \n",
       "50%       -0.203512      1.110848      0.134466     -0.003663      0.004158   \n",
       "75%        1.254102      3.700201      1.443666      0.662753      0.683465   \n",
       "max        8.542916     15.618988      7.575797      3.698010      3.963730   \n",
       "\n",
       "       ...           f20           f21           f22           f23  \\\n",
       "count  ...  15000.000000  15000.000000  15000.000000  15000.000000   \n",
       "mean   ...      0.008801      0.004798     -0.060611     -0.008095   \n",
       "std    ...      0.988931      0.999959      3.747823      0.994912   \n",
       "min    ...     -3.612116     -4.150852    -15.977469     -3.664246   \n",
       "25%    ...     -0.674236     -0.669654     -2.517892     -0.676471   \n",
       "50%    ...      0.020916      0.010701      0.019034     -0.001622   \n",
       "75%    ...      0.681036      0.676786      2.521745      0.659456   \n",
       "max    ...      3.497004      3.828639     12.661894      4.214633   \n",
       "\n",
       "                f24           f25           f26           f27           f28  \\\n",
       "count  15000.000000  15000.000000  15000.000000  15000.000000  15000.000000   \n",
       "mean       0.002397      0.699377     -0.001170      1.380216      0.150765   \n",
       "std        0.990567      3.801468      0.996588      3.929134      2.005847   \n",
       "min       -3.857890    -16.273835     -4.536600    -12.105957     -8.300728   \n",
       "25%       -0.661098     -1.842677     -0.668133     -1.339314     -1.235425   \n",
       "50%        0.001807      0.780608     -0.007763      1.108728      0.137089   \n",
       "75%        0.663270      3.297387      0.676626      3.869991      1.524830   \n",
       "max        4.378893     17.152063      3.618447     18.906060      8.007400   \n",
       "\n",
       "             target  \n",
       "count  15000.000000  \n",
       "mean       0.612600  \n",
       "std        0.740016  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max        2.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"S06-hw-dataset-03.csv\")\n",
    "df.head()\n",
    "df.info()\n",
    "df.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "835b2159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    8138\n",
       "1    4535\n",
       "2    2327\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values(ascending=False)\n",
    "\n",
    "df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9cdfce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 28), (15000,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"target\", \"id\"], errors = \"ignore\")\n",
    "y = df[\"target\"]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "324c9e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11250, 28), (3750, 28), np.float64(0.6125333333333334), np.float64(0.6128))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size = 0.25,\n",
    "    random_state = 42,\n",
    "    stratify = y\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0939aeee",
   "metadata": {},
   "source": [
    "мы фиксируем случайность разбиения, чтобы при каждом запуске получались одинаковые train/test. это нужно для правильного сравнения моделей и воспроизводимости результата\n",
    "\n",
    "стратификация важна, потому что она сохраняет пропорции классво в train и test. без этого можно случайно получить неправильный test, и метрики будут неверными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28948f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy_pred = dummy.predict(X_test)\n",
    "lb = LabelBinarizer()\n",
    "y_test_bin = lb.fit_transform(y_test)\n",
    "dummy_pred_bin = lb.transform(dummy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d114e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for dummy bro: 0.40453333333333336\n",
      "f1 for dummy bro: 0.3283980742103863\n",
      "auc for dummy bro: 0.496042196064942\n"
     ]
    }
   ],
   "source": [
    "roc_score = roc_auc_score(y_test_bin, dummy_pred_bin, multi_class='ovr', average='macro')\n",
    "accuracy = accuracy_score(y_test, dummy_pred)\n",
    "f1 = f1_score(y_test, dummy_pred, average=\"macro\")\n",
    "print(f\"accuracy for dummy bro: {accuracy}\")\n",
    "print(f\"f1 for dummy bro: {f1}\")\n",
    "print(f\"auc for dummy bro: {roc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce3f8a",
   "metadata": {},
   "source": [
    "dummy - это базовая нулевая модель, которая вообще не учится и выбирает самый частый класс. любая модель должна быть лучше этой глупой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "884d1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "\n",
    "logreg = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=2000, random_state=42))\n",
    "])\n",
    "logreg.fit(X_train, y_train)\n",
    "log_pred = logreg.predict(X_test)\n",
    "logreg_proba = logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c03adaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg accuracy: 0.72\n",
      "logreg f1: 0.6632634159041243\n",
      "logreg auc: 0.8467788482997881\n"
     ]
    }
   ],
   "source": [
    "logreg_acc = accuracy_score(y_test, log_pred)\n",
    "logreg_f1 = f1_score(y_test, log_pred, average=\"macro\")\n",
    "logreg_auc = roc_auc_score(y_test, logreg_proba, multi_class='ovr')\n",
    "print(f\"logreg accuracy: {logreg_acc}\")\n",
    "print(f\"logreg f1: {logreg_f1}\")\n",
    "print(f\"logreg auc: {logreg_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f85861e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# результаты baseline\n",
    "baseline_results = {\n",
    "    'Dummy_stratified': {\n",
    "        'accuracy': float(accuracy),\n",
    "        'f1_macro': float(f1),\n",
    "        'roc_auc_ovr': float(roc_score)\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'accuracy': float(logreg_acc),\n",
    "        'f1_macro': float(logreg_f1),\n",
    "        'roc_auc_ovr': float(logreg_auc)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b3222f",
   "metadata": {},
   "source": [
    "логистическая регрессия - довольно быстрый и сильный baseline. масштабирование признаков нужно, чтобы модель работала при разных порядков величин у фич."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "297b27ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "best params: {'ccp_alpha': 0.0, 'max_depth': 15, 'min_samples_leaf': 8}\n",
      "best CV score: 0.7277319032295219\n",
      "accuracy: 0.7957333333333333\n",
      "f1 (macro): 0.7489412237858829\n",
      "ROC-AUC (ovr): 0.8627944089902314\n",
      "depth: 15\n",
      "leaves: 546\n"
     ]
    }
   ],
   "source": [
    "dt_param_grid = {\n",
    "    'max_depth': [7, 10, 15],\n",
    "    'min_samples_leaf': [4, 8, 16],\n",
    "    'ccp_alpha': [0.0, 0.001, 0.01]\n",
    "}\n",
    "dt_grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    dt_param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"best params: {dt_grid.best_params_}\")\n",
    "print(f\"best CV score: {dt_grid.best_score_}\")\n",
    "\n",
    "dt_best = dt_grid.best_estimator_\n",
    "dt_test_pred = dt_best.predict(X_test)\n",
    "dt_test_accuracy = accuracy_score(y_test, dt_test_pred)\n",
    "dt_test_f1 = f1_score(y_test, dt_test_pred, average='macro')\n",
    "dt_test_proba = dt_best.predict_proba(X_test)\n",
    "dt_test_auc = roc_auc_score(y_test, dt_test_proba, multi_class='ovr')\n",
    "\n",
    "print(f\"accuracy: {dt_test_accuracy}\")\n",
    "print(f\"f1 (macro): {dt_test_f1}\")\n",
    "print(f\"ROC-AUC (ovr): {dt_test_auc}\")\n",
    "print(f\"depth: {dt_best.get_depth()}\")\n",
    "print(f\"leaves: {dt_best.get_n_leaves()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb50456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "search_summaries = {}\n",
    "\n",
    "model_results['DecisionTree'] = {\n",
    "    'accuracy': float(dt_test_accuracy),\n",
    "    'f1_macro': float(dt_test_f1),\n",
    "    'roc_auc_ovr': float(dt_test_auc)\n",
    "}\n",
    "search_summaries['DecisionTree'] = {\n",
    "    'best_params': dt_grid.best_params_,\n",
    "    'best_cv_score': float(dt_grid.best_score_)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "caee7b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "best params: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "best CV score: 0.8291\n",
      "accuracy: 0.8805\n",
      "f1 (macro): 0.8508\n",
      "ROC-AUC (ovr): 0.9502\n"
     ]
    }
   ],
   "source": [
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    rf_param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"best params: {rf_grid.best_params_}\")\n",
    "print(f\"best CV score: {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "rf_best = rf_grid.best_estimator_\n",
    "rf_test_pred = rf_best.predict(X_test)\n",
    "rf_test_accuracy = accuracy_score(y_test, rf_test_pred)\n",
    "rf_test_f1 = f1_score(y_test, rf_test_pred, average='macro')\n",
    "rf_test_proba = rf_best.predict_proba(X_test)\n",
    "rf_test_auc = roc_auc_score(y_test, rf_test_proba, multi_class='ovr')\n",
    "\n",
    "print(f\"accuracy: {rf_test_accuracy:.4f}\")\n",
    "print(f\"f1 (macro): {rf_test_f1:.4f}\")\n",
    "print(f\"ROC-AUC (ovr): {rf_test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c1450",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results['RandomForest'] = {\n",
    "    'accuracy': float(rf_test_accuracy),\n",
    "    'f1_macro': float(rf_test_f1),\n",
    "    'roc_auc_ovr': float(rf_test_auc)\n",
    "}\n",
    "search_summaries['RandomForest'] = {\n",
    "    'best_params': rf_grid.best_params_,\n",
    "    'best_cv_score': float(rf_grid.best_score_)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d161911",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_best.feature_importances_\n",
    "}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c23baf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      2\u001b[39m gb_param_grid = {\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m50\u001b[39m, \u001b[32m100\u001b[39m],\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.01\u001b[39m, \u001b[32m0.05\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msubsample\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.8\u001b[39m, \u001b[32m0.9\u001b[39m]\n\u001b[32m      8\u001b[39m }\n\u001b[32m     10\u001b[39m gb_grid = GridSearchCV(\n\u001b[32m     11\u001b[39m     GradientBoostingClassifier(random_state=\u001b[32m42\u001b[39m),\n\u001b[32m     12\u001b[39m     gb_param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mgb_grid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbest params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgb_grid.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbest CV score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgb_grid.best_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RaynoR\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RaynoR\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1053\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1047\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1048\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1049\u001b[39m     )\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1057\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RaynoR\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1612\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1610\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1611\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1612\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RaynoR\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:999\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    992\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    993\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    994\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    995\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    996\u001b[39m         )\n\u001b[32m    997\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m999\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1021\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1022\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RaynoR\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RaynoR\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RaynoR\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RaynoR\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.05],\n",
    "    'max_depth': [3, 5],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'subsample': [0.8, 0.9]\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    gb_param_grid,\n",
    "    cv=2,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"best params: {gb_grid.best_params_}\")\n",
    "print(f\"best CV score: {gb_grid.best_score_:.4f}\")\n",
    "\n",
    "gb_best = gb_grid.best_estimator_\n",
    "gb_test_pred = gb_best.predict(X_test)\n",
    "gb_test_accuracy = accuracy_score(y_test, gb_test_pred)\n",
    "gb_test_f1 = f1_score(y_test, gb_test_pred, average='macro')\n",
    "gb_test_proba = gb_best.predict_proba(X_test)\n",
    "gb_test_auc = roc_auc_score(y_test, gb_test_proba, multi_class='ovr')\n",
    "\n",
    "\n",
    "print(f\"accuracy: {gb_test_accuracy:.4f}\")\n",
    "print(f\"f1 (macro): {gb_test_f1:.4f}\")\n",
    "print(f\"ROC-AUC (ovr): {gb_test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results['GradientBoosting'] = {\n",
    "    'accuracy': float(gb_test_accuracy),\n",
    "    'f1_macro': float(gb_test_f1),\n",
    "    'roc_auc_ovr': float(gb_test_auc)\n",
    "}\n",
    "search_summaries['GradientBoosting'] = {\n",
    "    'best_params': gb_grid.best_params_,\n",
    "    'best_cv_score': float(gb_grid.best_score_)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c516af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {**baseline_results, **model_results}\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(all_results).T\n",
    "results_df_sorted = results_df.sort_values('f1_macro', ascending=False)\n",
    "print(\"по F1-score (макро):\")\n",
    "\n",
    "for i, (model, row) in enumerate(results_df_sorted.iterrows(), 1):\n",
    "    print(f\"{i}. {model:20} : f1={row['f1_macro']:.4f}, accuracy={row['accuracy']:.4f}\")\n",
    "    \n",
    "best_model_name = results_df_sorted.index[0]\n",
    "best_model_score = results_df_sorted.iloc[0]['f1_macro']\n",
    "\n",
    "print(f\"\\nbest model: {best_model_name}\")\n",
    "print(f\"f1-score (macro): {best_model_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f2b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rf_best\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.colorbar()\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, str(cm[i, j]), ha='center', va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f731d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "ax1 = axes[0]\n",
    "models = results_df_sorted.index\n",
    "acc_values = results_df_sorted['accuracy'].values\n",
    "bars1 = ax1.bar(models, acc_values, color='skyblue', edgecolor='black')\n",
    "ax1.set_title('Accuracy сравнение моделей')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, val in zip(bars1, acc_values):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "            f'{val:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "ax2 = axes[1]\n",
    "f1_values = results_df_sorted['f1_macro'].values\n",
    "bars2 = ax2.bar(models, f1_values, color='lightcoral', edgecolor='black')\n",
    "ax2.set_title('F1-score (macro) сравнение моделей')\n",
    "ax2.set_ylabel('F1-score')\n",
    "ax2.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "for bar, val in zip(bars2, f1_values):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "            f'{val:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/metrics_comparison.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7bb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nВажность признаков RandomForest\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_n = min(10, len(feature_importance))\n",
    "top_features = feature_importance.head(top_n)\n",
    "\n",
    "plt.barh(range(top_n), top_features['importance'].values)\n",
    "plt.yticks(range(top_n), top_features['feature'].values)\n",
    "plt.xlabel('Важность признака')\n",
    "plt.title(f'Топ-{top_n} важных признаков RandomForest')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/feature_importance.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21efd5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Лучшая модель: {best_model_name}\")\n",
    "print(f\"Лучшие параметры: {search_summaries.get(best_model_name, {}).get('best_params', 'N/A')}\")\n",
    "\n",
    "print(\n",
    "    \"Все рассмотренные модели показали качество выше Dummy baseline.\\n\"\n",
    "    \"Ансамблевые методы (RandomForest, AdaBoost) продемонстрировали более стабильные и высокие значения метрик по сравнению с одиночным деревом.\\n\"\n",
    "    \"Ограничение сложности DecisionTree (через max_depth и min_samples_leaf) позволило снизить переобучение и улучшить обобщающую способность модели.\\n\\n\"\n",
    "    \"Интерпретация влияния признаков:\\n\"\n",
    "    \"- Признаки с высокой permutation importance оказывают наибольшее влияние на итоговые предсказания модели.\\n\"\n",
    "    \"- Признаки с близкой к нулю важностью вносят минимальный вклад и потенциально могут быть исключены без заметной потери качества.\\n\"\n",
    "    \"- Наличие отрицательных значений permutation importance указывает на шумовые или мешающие признаки, удаление которых может улучшить метрики модели.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('artifacts/metrics_test.json', 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "\n",
    "with open('artifacts/search_summaries.json', 'w') as f:\n",
    "    json.dump(search_summaries, f, indent=2)\n",
    "\n",
    "if best_model_name != 'Dummy_stratified':\n",
    "    joblib.dump(best_model, 'artifacts/best_model.joblib')\n",
    "\n",
    "best_model_meta = {\n",
    "    'best_model_name': best_model_name,\n",
    "    'best_model_params': search_summaries.get(best_model_name, {}).get('best_params', {}),\n",
    "    'test_metrics': all_results.get(best_model_name, {}),\n",
    "    'cv_score': search_summaries.get(best_model_name, {}).get('best_cv_score', None),\n",
    "    'task_type': 'multiclass',\n",
    "    'dataset': 'S06-hw-dataset-03.csv',\n",
    "    'timestamp': pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "with open('artifacts/best_model_meta.json', 'w') as f:\n",
    "    json.dump(best_model_meta, f, indent=2)\n",
    "\n",
    "results_df_sorted.to_csv('artifacts/metrics_comparison.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
